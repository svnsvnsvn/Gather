{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66bd65dd",
   "metadata": {},
   "source": [
    "# Phase 1: Simple Garbage Classification with MobileNetV2\n",
    "\n",
    "**Goal**: Build a working 12-category waste classifier using the Kaggle dataset\n",
    "\n",
    "**Dataset**: 15,515 images across 12 categories:\n",
    "- battery, biological, brown-glass, cardboard, clothes, green-glass\n",
    "- metal, paper, plastic, shoes, trash, white-glass\n",
    "\n",
    "**Target**: >85% validation accuracy, deployable model\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd75f4e2",
   "metadata": {},
   "source": [
    "## 1. Environment Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091a73b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU available: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158b5882",
   "metadata": {},
   "source": [
    "## 2. Dataset Loading & Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be29e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset configuration\n",
    "DATASET_PATH = \"../data/Kaggle/garbage_classification\"\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "VALIDATION_SPLIT = 0.2\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    DATASET_PATH,\n",
    "    validation_split=VALIDATION_SPLIT,\n",
    "    subset=\"training\",\n",
    "    seed=42,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "val_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    DATASET_PATH,\n",
    "    validation_split=VALIDATION_SPLIT,\n",
    "    subset=\"validation\",\n",
    "    seed=42,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "class_names = train_dataset.class_names\n",
    "num_classes = len(class_names)\n",
    "\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "print(f\"Class names: {class_names}\")\n",
    "print(f\"Training batches: {tf.data.experimental.cardinality(train_dataset)}\")\n",
    "print(f\"Validation batches: {tf.data.experimental.cardinality(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7943e679",
   "metadata": {},
   "source": [
    "## 3. Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63fee64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample images\n",
    "plt.figure(figsize=(15, 10))\n",
    "for images, labels in train_dataset.take(1):\n",
    "    for i in range(min(16, len(images))):\n",
    "        plt.subplot(4, 4, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(f\"{class_names[labels[i]]}\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5313ce6f",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing & Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb45ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation for training\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "    tf.keras.layers.RandomRotation(0.1),\n",
    "    tf.keras.layers.RandomZoom(0.1),\n",
    "    tf.keras.layers.RandomBrightness(0.1),\n",
    "    tf.keras.layers.RandomContrast(0.1)\n",
    "])\n",
    "\n",
    "# Preprocessing for MobileNetV2\n",
    "preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\n",
    "\n",
    "# Optimize dataset performance\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "def prepare_dataset(ds, shuffle=False, augment=False):\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(1000)\n",
    "    \n",
    "    # Resize and rescale\n",
    "    ds = ds.map(lambda x, y: (tf.cast(x, tf.float32), y), num_parallel_calls=AUTOTUNE)\n",
    "    \n",
    "    if augment:\n",
    "        ds = ds.map(lambda x, y: (data_augmentation(x, training=True), y), num_parallel_calls=AUTOTUNE)\n",
    "    \n",
    "    # MobileNetV2 preprocessing\n",
    "    ds = ds.map(lambda x, y: (preprocess_input(x), y), num_parallel_calls=AUTOTUNE)\n",
    "    \n",
    "    return ds.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "train_ds = prepare_dataset(train_dataset, shuffle=True, augment=True)\n",
    "val_ds = prepare_dataset(val_dataset)\n",
    "\n",
    "print(\"Datasets prepared successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52564ac",
   "metadata": {},
   "source": [
    "## 5. Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db26b48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    # Load pre-trained MobileNetV2\n",
    "    base_model = tf.keras.applications.MobileNetV2(\n",
    "        input_shape=IMG_SIZE + (3,),\n",
    "        include_top=False,\n",
    "        weights='imagenet'\n",
    "    )\n",
    "    \n",
    "    # Freeze base model initially\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    # Add custom classifier head\n",
    "    model = tf.keras.Sequential([\n",
    "        base_model,\n",
    "        tf.keras.layers.GlobalAveragePooling2D(),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax', name='predictions')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "\n",
    "# Compile model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8355e24b",
   "metadata": {},
   "source": [
    "## 6. Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19fc0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        '../models/phase1_best_model.h5',\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        mode='max',\n",
    "        verbose=1\n",
    "    ),\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=3,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"Training callbacks configured.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbed752",
   "metadata": {},
   "source": [
    "## 7. Initial Training (Transfer Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0cad86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with frozen base model first\n",
    "print(\"Starting initial training with frozen base model...\")\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=10,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Initial training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c8ca8f",
   "metadata": {},
   "source": [
    "## 8. Fine-tuning (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5a5bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze top layers for fine-tuning\n",
    "base_model = model.layers[0]\n",
    "base_model.trainable = True\n",
    "\n",
    "# Fine-tune from this layer onwards\n",
    "fine_tune_at = 100\n",
    "\n",
    "# Freeze all layers before fine_tune_at\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Recompile with lower learning rate\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001/10),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(f\"Fine-tuning {len([l for l in base_model.layers if l.trainable])} layers...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e31ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue training with fine-tuning\n",
    "fine_tune_epochs = 5\n",
    "total_epochs = len(history.history['loss']) + fine_tune_epochs\n",
    "\n",
    "history_fine = model.fit(\n",
    "    train_ds,\n",
    "    epochs=total_epochs,\n",
    "    initial_epoch=len(history.history['loss']),\n",
    "    validation_data=val_ds,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Fine-tuning complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56ed409",
   "metadata": {},
   "source": [
    "## 9. Results Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c6ef29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "def plot_training_history(history, history_fine=None):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    \n",
    "    if history_fine:\n",
    "        acc += history_fine.history['accuracy']\n",
    "        val_acc += history_fine.history['val_accuracy']\n",
    "        loss += history_fine.history['loss']\n",
    "        val_loss += history_fine.history['val_loss']\n",
    "    \n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(acc, label='Training Accuracy')\n",
    "    plt.plot(val_acc, label='Validation Accuracy')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(loss, label='Training Loss')\n",
    "    plt.plot(val_loss, label='Validation Loss')\n",
    "    plt.title('Model Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print final metrics\n",
    "    print(f\"Final Training Accuracy: {acc[-1]:.4f}\")\n",
    "    print(f\"Final Validation Accuracy: {val_acc[-1]:.4f}\")\n",
    "    print(f\"Final Training Loss: {loss[-1]:.4f}\")\n",
    "    print(f\"Final Validation Loss: {val_loss[-1]:.4f}\")\n",
    "\n",
    "try:\n",
    "    plot_training_history(history, history_fine)\n",
    "except:\n",
    "    plot_training_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac22514",
   "metadata": {},
   "source": [
    "## 10. Model Evaluation & Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7364a8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on validation set\n",
    "val_loss, val_accuracy = model.evaluate(val_ds)\n",
    "print(f\"Validation accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "# Make predictions on a batch\n",
    "predictions = model.predict(val_ds.take(1))\n",
    "print(f\"Prediction shape: {predictions.shape}\")\n",
    "\n",
    "# Show prediction confidence\n",
    "for images, labels in val_ds.take(1):\n",
    "    pred_probs = model.predict(images[:8])\n",
    "    pred_classes = np.argmax(pred_probs, axis=1)\n",
    "    \n",
    "    plt.figure(figsize=(16, 8))\n",
    "    for i in range(8):\n",
    "        plt.subplot(2, 4, i + 1)\n",
    "        plt.imshow((images[i].numpy() * 0.5 + 0.5))  # Denormalize for display\n",
    "        \n",
    "        true_label = class_names[labels[i]]\n",
    "        pred_label = class_names[pred_classes[i]]\n",
    "        confidence = np.max(pred_probs[i]) * 100\n",
    "        \n",
    "        color = 'green' if pred_classes[i] == labels[i] else 'red'\n",
    "        plt.title(f\"True: {true_label}\\nPred: {pred_label} ({confidence:.1f}%)\", color=color)\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eaadc94",
   "metadata": {},
   "source": [
    "## 11. Save Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a3f9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final model\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "model_name = f\"../models/phase1_final_model_{timestamp}.h5\"\n",
    "\n",
    "model.save(model_name)\n",
    "print(f\"Model saved as: {model_name}\")\n",
    "\n",
    "# Save class names for later use\n",
    "import json\n",
    "with open('../models/class_names.json', 'w') as f:\n",
    "    json.dump(class_names, f)\n",
    "print(\"Class names saved.\")\n",
    "\n",
    "# Model summary\n",
    "print(f\"\\n=== PHASE 1 COMPLETE ===\")\n",
    "print(f\"Final validation accuracy: {val_accuracy:.4f}\")\n",
    "print(f\"Target achieved: {val_accuracy >= 0.85}\")\n",
    "print(f\"Model ready for deployment: {model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8340c9",
   "metadata": {},
   "source": [
    "## Next Steps for Phase 2\n",
    "\n",
    "1. **Web Integration**: Connect this model to the existing HTML interface\n",
    "2. **Performance Optimization**: Convert to TensorFlow Lite for faster inference\n",
    "3. **Error Analysis**: Identify challenging categories and improve with targeted data\n",
    "4. **Real-world Testing**: Collect and test on images outside the training distribution\n",
    "\n",
    "---\n",
    "*Phase 1 Goal: Get a working classifier deployed. âœ“*"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
